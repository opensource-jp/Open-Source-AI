# よくある質問への回答
最終更新日 2024年10月22日

# :warning: この文書はまだ作成中です :warning:

## オープンソースAIとは何ですか？

TL;DR: オープンソースAIとは、Open Source Initiative(OSI)が承認した法的条件の下で、必要な全てのコード、データ、パラメータが自由に利用できるAIシステムのことです。詳細は以下をご覧ください。

## なぜオープンソースAIの定義が作成されたのですか？

[オープンソースの定義](https://opensource.org/osd)(OSD: Open Source Definition)の第2条に「プログラムはソースコードを含んでいなければならず、... (略) ソースコードは、プログラマがプログラムを変更する際に優先される形式でなければなりません」とあります。AIシステムを修正する際に優先される形式とは何かについて、明確な答えを持っている人は誰もいませんでした。そこで、OSIは[共同設計プロセス](https://opensource.org/deepdive/)に関わるコミュニティとともに、その答えを見つけることを提案しました。

## オープンソースの定義とオープンソースAIの定義の違いは何ですか？

[オープンソースの定義](https://opensource.org/osd)は、ソフトウェア・プログラムに言及しています。AI、特に機械学習システムは、単なるソフトウェア・プログラムではなく、データ、構成オプション、ドキュメント、重みやバイアスなどの新しいアーティファクトとの境界が混在しています。オープンソースAIの定義は、AIシステムに改変を加えるための推奨される形式を説明し、OSDの原則をAIの領域で解釈するための明確性を提供します。


## オープンソースAIの定義におけるトレーニングデータの役割とは何でしょうか？

オープンソースとは、追加の許可を必要とせずに、誰でもあなたのシステムを有意義にフォーク(研究および改変)し、自分自身や他の人々にとってより有用なものにできる能力を与えることを意味します。これが、OSD第2条が改変を行うための推奨される形式でソースコードを提供することを要求する理由です。これにより、誰もがオリジナルの開発者と同じ権利とフォークの能力を持ち、イノベーションの好循環が始まります。

しかし、トレーニング・データはソフトウェアのソースコードと同じではありません。トレーニング・データは、最新の機械学習システムを研究する上で重要です。ただし、AI の研究者や実践者が、トレーニング済みモデルに改変を加えるための推奨される形式の一部として必ず使用するものではありません。

データ情報およびコードの要件により、第三者のAI開発者はオリジナルの開発者と同じ情報を使用し、下流でオープンソースAIシステムをフォークすることができます。これらのフォークには、完全に公開またはオープンデータで新しいオープンソースAIシステムをトレーニングするために、トレーニング・データセットから非公開または非オープンなデータを削除することが含まれます。

### 一部のトレーニング データを除外できるのは何故ですか？

何故なら、私たちは医療AIなど、データが合法的に共有できない分野にもオープンソースAIが存在することを望んでいるからです。データのトレーニングを許可する法律は、著作権やその他の利益を保護するために、同じデータの再共有を制限することがよくあります。プライバシーに関する規則も、健康に関する決定など個人の最も機密性の高い情報を管理する正当な権限を個人に与えるものです。同様に、世界の先住民族の知識の多くは、後に開発された独占的権利や共有の枠組みと互換性のないメカニズムによって保護されています。

また、一般に公開されているデータの利用規約が、Aという存在に「自由に利用できる」という確証を与え、「オープンデータ」と呼ぶことを可能にしている場合でも、Aという存在が別の管轄区域においてBという存在に確証を与えることができるという保証を与えない場合も多くあります。一方、Bという存在は、自らの管轄区域でそのデータを使用することに確信がある場合もあれば、ない場合もあります。一例として、いわゆるパブリックドメインのデータにおいては、パブリックドメインの定義が国によって異なります。このような再共有は、限定的であるというよりも、[法的確実性を欠いている](https://opensource.org/blog/copyright-law-makes-a-case-for-requiring-data-information-rather-than-open-datasets-for-open-source-ai)といえます。


### どのようにしてこの結論に至ったのですか? これはオープンソースの理想を妥協するものでしょうか?

OSAIDの共同設計プロセスにおいて、重みとデータの関係性がコミュニティの関与を最も促す結果となりました。「[システム分析](https://discuss.opensource.org/t/report-on-working-group-recommendations/247)」のフェーズでは、ボランティアグループは、トレーニング・データやテストデータにアクセスするよりも、トレーニング・コードやデータ処理コードを修正する方がAIシステムを変更する上でより重要であると示唆しました。その結果は「[検証フェーズ](https://discuss.opensource.org/t/initial-report-on-definition-validation/368)」でさらに検証され、オープンソースAIがプロプライエタリなシステムと対等の立場で存在できる道筋を示しました。つまり、両者は同じ[種類のデータ](#What-kind-of-data-should-be-required-in-the-Open-Source-AI-Definition)でトレーニングを行うことができるということです。

全てのトレーニングデータ([種類](#What-kind-of-data-should-be-required-in-the-Open-Source-AI-Definition)による区別なし)への完全かつ無制限のアクセスが最も重要であり、それ以下ではAIシステムの完全な再現性、透明性、安全性が損なわれると主張する一部の人々もいます。このアプローチでは、オープンソースAIはオープンデータのみでトレーニング可能なAIのニッチな分野に追いやられてしまいます([FAQ](#What-kind-of-data-should-be-required-in-the-Open-Source-AI-Definition)を参照)。そのニッチな分野は、従来のソフトウェアエコシステムにおけるオープンソースのニッチな分野と比較しても、非常に小さなものになるでしょう。データ情報に関する要件は、完全な再現性と透明性を義務づけるものではないが、それらを可能にする(つまり、[再現可能なビルド](https://reproducible-builds.org/))というオープンソースの定義に存在するアプローチを維持します。同時に、データ情報を必須とするベースラインを設定することは、[デジタル公共財標準](https://digitalpublicgoods.net/standard/)や[自由なシステム・ディストリビューションのガイドライン](https://www.gnu.org/distros/free-system-distribution-guidelines.html)がオープンソースの定義に要件を追加しているように、他者がより多くの要件を策定し、要求することを妨げるものではありません。

OSIの使命の重要な側面のひとつは、オープンソースのイノベーションを推進し、促進することです。ここでOSIは採用するアプローチは、オープンソースAIにおける完全なユーザーの選択を可能にします。ユーザーは、トレーニング+データ前処理コードおよび共有不可のトレーニングデータの説明から得られた洞察を保持し、それらを自身の共有不可のデータを使用してそれらを構築し、さらにトレーニングから得られた洞察を全ての人に提供することで、ヘルスケアなどの分野におけるオープンソースAIを実現することができます。あるいは、ユーザーはデータ情報から入手可能な公開データを使用して、非共有データなしでモデルを再トレーニングし、その結果、AIシステムにおけるデータの透明性をより高めることができます。コピーレフトや寛容ライセンスと同様に、このアプローチではユーザーに選択が委ねられます。

### オープンソースAIの定義ではどのような種類のデータが必要でしょうか？

法的制約に基づいて、4つのデータのクラスに分類され、それらはオープンソースAIシステムのトレーニングに使用できます:

* **オープンなトレーニングデータ**: 複製、保存、変更、再共有が可能なデータ。ユーザーがシステムを研究する上で最善の方法を提供します。これは共有する必要があります。
* **公開トレーニングデータ**: 利用可能である限り、他のユーザーが検査できるデータ。これにより、ユーザーはその作業を研究することもできます。ただし、このデータは、ネットワーク上でリンクや参照が失われたり削除されたりすると劣化する可能性があります。これを回避するには、異なるコミュニティが協力して、このリスクを克服するための標準、手順、ツール、ガバナンスモデルを定義する必要があります。また、後にデータが利用できなくなった場合に備えて、データ情報が必要となります。これは、入手先の詳細を全て開示しなければなりません。
* **入手可能なトレーニングデータ**: 有料のものも含め、入手可能なデータ。この情報は透明性を提供し、オープンハードウェアシステムにおける購入可能なコンポーネントに類似しています。データ情報は、このデータを入手または購入する以外の方法で理解する手段を提供します。これは急速に変化する可能性が高い領域であり、オープンソースAI開発者を保護するために注意深い監視が必要になります。これは、入手先の詳細を全て開示しなければなりません。
* **共有不可の非公開トレーニングデータ**: 個人を特定できる情報(PII:Personally Identifiable Information)など、説明可能な理由により共有できないデータ。このクラスのデータについては、システムのバイアスの一部を研究する能力には、データの詳細な説明（それが何であるか、どのように収集されたか、その特性など）が求められるため、ユーザーはシステムの根底にあるバイアスや分類を理解することができます。この点について詳細を明らかにしなければならず。例えば、病院が独自の患者データを使用して、同じ構造のデータセットを作成できるようにするためなどです。

OSIは、これらの全ての種類のデータが、AIシステムに推奨される改変を加えるための一部となり得ると考えています。このアプローチは、AIシステムの全てのコンポーネントにおけるオープン性を向上させ、ヘルスケアなどのプライベート優先の分野でのオープンソースAIをさらに推進します。

## 熟練者(skilled person)とは何ですか？

法律の世界では、熟練者(**Skilled Person**)とは、特定の職務を遂行するのに必要な最新の知識、経験、能力を有する人物を意味します。この[Wikipediaのエントリ](https://en.wikipedia.org/wiki/Person_having_ordinary_skill_in_the_art)(日本語版Wikipediaでは「当業者」のエントリとなるが、OSAID日本語訳では敢えて一般的な用語である熟練者を訳語として採用した)に詳細が記載されています。

## オープンソースAIの定義は、モデルや重み、パラメータも対象としているのでしょうか？

はい。オープンソースAIの定義では、AIシステム、モデル、重みとパラメータと呼ばれるものを区別していません。オープンソースAIと呼ばれるためには、提供物がAIシステム、モデル、重みやパラメータのいずれの特徴を持つものであっても、改変を可能にする推奨される形式を提供するための要件は同じです。

## OSD第2条ではコンパイラを必須としていないのに、何故トレーニングコードが必要なのですか？

AIとソフトウェアは根本的に異なる領域であり、両者を比較することはほとんど生産的ではありません。コンパイラが規則上(ANSI Cのような)または事実上(TurboPascalやPythonのような)の標準化がされているため、OSD第2条では、オープンソースのソフトウェアがOSI承認ライセンスでリリースされたコンパイラのみを使用することを義務付けていません。より多くのオープンソースソフトウェアを開発するには、プロプライエタリな開発環境の使用を受け入れることも可能であると一般的に受け入れられていました。機械学習の場合、トレーニングコードは標準化されていないため、AIシステムをフォークする権利を維持するために改変を加えるための推奨される形式の一部でなければなりません。

## オープンソースAIの定義では、安全性やリスクの制限について言及されていないのは何故ですか？

オープンソースAIの定義は、倫理的、信頼性、または責任あるAI開発の実践を具体的に指導したり、強制したりするものではありません。しかし、開発者がそうすることを選択した場合に、そのような原則に従うことを妨げる障壁を設けるものではありません。適切な政府規制を含むAIシステムの責任ある開発、展開、使用について議論する取り組みは、別の問題です。良い出発点は、OECDの「人工知能に関する理事会勧告」の[第1章「信頼できるAIの責任ある管理のための原則」](https://legalinstruments.oecd.org/en/instruments/oecd-legal-0449)である

## モデルパラメータは著作権保護の対象となりますか？

オープンソースAIの定義は、パラメータの法的性質についていかなる立場もとっていません。パラメータは、その性質上、自由であるかもしれないし、自由を保証するためにライセンスやその他の法的手段が必要となるかもしれない。法制度がこれらの問題に対処する機会が増えれば、時間の経過とともに明確になるものと期待しています。いずれにしても、パラメータの頒布には、それが全ての人に自由に利用可能であることを保証する明示的な表明が必要です。

## 「改変を加えるための推奨される形式」が機械学習に限定されているのは何故ですか？

オープンソースAIの定義で述べられている原則は一般的にあらゆる種類のAIに適用できますが、オープンソースの定義に課題を投げかけているのは機械学習です。機械学習の場合、システムを研究し改変するために必要な一連の成果物(コンポーネント)があるため、システムを研究し改変するために何が必要かについて、新たな説明が必要となります。

## どのAIシステムがオープンソースAIの定義に準拠していますか?

OSAIDの検証およびテストの一環として、ボランティアは、AIシステムが期待される自由を提供しているかどうかを評価する際に、この定義が使用できるかどうかを確認しました。検証フェーズに合格したモデルの一覧は次のとおりです:Pythia(Eleuther AI)、OLMo(AI2)、AmberおよびCrystalCoder(LLM360)、T5(Google)。分析済みでライセンスまたは法的条件を変更すればおそらく合格すると思われるもの:BLOOM(BigScience)、Starcoder2 (BigCode)、Falcon(TII)。分析済みで必要なコンポーネントが欠如しているか、または法的条件がオープンソースの原則と適合しないため不合格となったもの:Llama2(Meta)、Grok(X/Twitter)、Phi-2(Microsoft)、Mixtral(Mistral)。
これらの結果は、定義作成プロセスの一部であり、学習の機会と見做すべきであり、いかなる種類の認証でもありません。OSIは、ソフトウェアのプロジェクトを検証またはレビューしないのと同様に法的文書のみを検証し続け、個々のAIシステムを検証またはレビューすることはありません。
